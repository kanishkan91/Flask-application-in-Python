{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import commands\n",
    "\n",
    "from flask import Flask, flash, redirect, render_template, request, session, abort\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import xlrd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "#Main code\n",
    "\n",
    "#1. Define app\n",
    "app= Flask(__name__)\n",
    "\n",
    "\n",
    "#2. Create route, homepage and pull in data (Please change path to data as you see fit)\n",
    "@app.route(\"/\",methods=[\"GET\",\"POST\"])\n",
    "def homepage():\n",
    "#kbn 2018/12/12-Start- Call value from HTML form\n",
    "  data1 = request.form.get('question1_field','Education')\n",
    "  params = data1\n",
    "#kbn 2018/12/12-End\n",
    "  pd.set_option('display.max_rows', None)\n",
    "  pd.set_option('display.max_columns', None)\n",
    "  datasource1 = pd.read_excel(\"C:/Users/Public/Rfiles/Data_for_Similarity_New.xlsx\")\n",
    "  datasource1 = pd.DataFrame(datasource1)\n",
    "\n",
    "#3. Divide the input words into multiple words and write a loop to filter dataset for words in the \"Text\" column\n",
    "#kbn 2018/12/12-Start- Here divide inputs into multiple words and filter data using words to narrow sample size\n",
    "  words = data1.split()\n",
    "\n",
    "  datasource2 = []\n",
    "  for i in words:\n",
    "      print(i)\n",
    "      d2 = datasource1[datasource1['Text'].str.contains(str(i))]\n",
    "      datasource2.append(d2)\n",
    "\n",
    "  datasource2 = pd.concat(datasource2, ignore_index=True)\n",
    "\n",
    "  datasource2 = pd.DataFrame(datasource2)\n",
    "  datasource2=datasource2.drop_duplicates()\n",
    "  datasource2=datasource2.reset_index()\n",
    "  #print(datasource.head())\n",
    "#kbn 2018/12/12-End\n",
    "\n",
    "#4. Start computation of similarilty score here\n",
    "  datasource=datasource2\n",
    "  index_source = 0\n",
    "  max_simi = 0\n",
    "\n",
    "  for i in range(0, len(datasource)):\n",
    "      documents = []\n",
    "      documents.append(params)\n",
    "      documents.append(datasource.loc[i, 'Text'])\n",
    "# kbn 2018/12/12-Start- add stop_words and ngram_range to the TfidVectorizer below\n",
    "      tfidf = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 4)).fit_transform(documents)\n",
    "# kbn 2018/12/12-End\n",
    "      # no need to normalize, since Vectorizer will return normalized tf-idf\n",
    "      pairwise_similarity = tfidf * tfidf.T\n",
    "      # Add stop word, Add ngram\n",
    "\n",
    "      temp = pairwise_similarity.A[0][1]\n",
    "\n",
    "      simiscore = \"{0:.4f}\".format(temp)\n",
    "      print(simiscore)\n",
    "      datasource.loc[i, 'Simiscore'] = simiscore\n",
    "\n",
    "  datasource['Rank'] = datasource['Simiscore'].rank(method='average', ascending=False)\n",
    "  datasource = datasource.sort_values('Rank', ascending=True)\n",
    "  datasource = datasource.head(10)\n",
    "  datasource = datasource.reset_index()\n",
    "\n",
    "  # select some needed columns to display\n",
    "  datadisplay = datasource[\n",
    "      [\"Rank\", \"ProjectName\", \"Organization\", \"Country\", \"Sector\", \"Year\", \"Practitioner\", \"ProjectID\",\"Text\",\n",
    "       \"Simiscore\"]]\n",
    "  datadisplay.Rank = datadisplay.Rank.astype(np.int64)\n",
    "\n",
    "  datadisplay=datadisplay.to_json(orient=\"records\")\n",
    "\n",
    "#5. Define return here (I am returning as json since that is the best for the html file)\n",
    "  return render_template('documents.html', docs=json.loads(datadisplay))\n",
    "\n",
    "#6. Run app below\n",
    "#debugger turned off below since this is a jupyter notebook\n",
    "if __name__ == \"__main__\":\n",
    "  app.debug = False\n",
    "  app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
